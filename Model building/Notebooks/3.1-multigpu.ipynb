{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch on multiple gpus\n",
    "\n",
    "For AlexNet:\n",
    "- Two GTX 580 GPUs with 3GB memory (on HPC we can select up to 8 GPU's per node.)\n",
    "- The network takes 90 epochs in five or six days to train on two GTX 580 GPUs. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#PBS -l walltime=0:30:0\n",
    "#PBS -l select=1:ncpus=4:mem=2gb:ngpus=2:gpu_type=RTX6000\n",
    "\n",
    "\n",
    "module load anaconda3/personal\n",
    "source activate interiorcardamage\n",
    "\n",
    "cd $PBS_O_WORKDIR\n",
    "torchrun --standalone --nproc_per_node=2 multipgu_torchrun.py 50 10\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```--standalone``` means we are using one node\n",
    "```--nproc_per_node=gpu``` number of gpus per node. Equalling this to ```gpu``` would let torchrun use the maximum number\n",
    "We run 50 epochs taking a snapshot every 10th epoch.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
