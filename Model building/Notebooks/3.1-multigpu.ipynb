{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch on multiple gpus\n",
    "\n",
    "For AlexNet:\n",
    "- Two GTX 580 GPUs with 3GB memory (on HPC we can select up to 8 GPU's per node.)\n",
    "- The network takes 90 epochs in five or six days to train on two GTX 580 GPUs. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#PBS -l walltime=0:30:0\n",
    "#PBS -l select=1:ncpus=4:mem=2gb:ngpus=2:gpu_type=RTX6000\n",
    "\n",
    "\n",
    "module load anaconda3/personal\n",
    "source activate interiorcardamage\n",
    "\n",
    "cd $PBS_O_WORKDIR\n",
    "torchrun --standalone --nproc_per_node=2 multipgu_torchrun.py 50 10\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```--standalone``` means we are using one node\n",
    "```--nproc_per_node=gpu``` number of gpus per node. Equalling this to ```gpu``` would let torchrun use the maximum number\n",
    "We run 50 epochs taking a snapshot every 10th epoch.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the accuracy on multigpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image folder: 81\n",
      "train loader: 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib\n",
    "\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#print(device)\n",
    "\n",
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(), # flips image with p=0.5 to augment data\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "                        [0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "train_path = 'C:/Users/hanna/Desktop/git/interiorcardamage/Data/train'\n",
    "test_path = 'C:/Users/hanna/Desktop/git/interiorcardamage/Data/test'\n",
    "\n",
    "image_folder_train = torchvision.datasets.ImageFolder(root=train_path, transform=transformer)\n",
    "image_folder_test = torchvision.datasets.ImageFolder(root=test_path, transform=transformer)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(\n",
    "    image_folder_train,\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "test_loader=torch.utils.data.DataLoader(\n",
    "    image_folder_test,\n",
    "    batch_size=32, shuffle=True\n",
    ")\n",
    "\n",
    "#print('data loaded')\n",
    "\n",
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "\n",
    "print('image folder: '+ str(len(image_folder_train))) # gives the TOTAL number of images/ datapoints\n",
    "print('train loader: '+ str(len(train_loader))) # gives the number of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyTrainDataset(Dataset):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.data = [(torch.rand(20), torch.rand(1)) for _ in range(size)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "train_set = MyTrainDataset(2048)\n",
    "len(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_p37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
